k8 architecture
--------------------
master and nodes

master
===========
api server --> all  cluster interactions comes to api server. validates RBAC and provide the response. if you are creating pods, api server validates and handover to scheduler.

scheduler --> it a component to decide where your pod should run. it checks for taints and tolerations, selectors like nodeaffinity, pod affinity, node readiness,etc.

control manager
replica controller -> make sures desired number of pod replicas run all the time.
node controller --> checks desired number of nodes are running
Job controller --> A Job runs a Pod (or multiple Pods) until the work is finished successfully â€” then it stops.
ServiceAccount controller --> Create default ServiceAccounts for new namespaces.
EndpointSlice controller -> Populates EndpointSlice objects (to provide a link between Services and Pods).

etcd --> key value storage for k8 cluster. all k8 configs are here
ðŸ§  What is etcd in Kubernetes?

âž¡ï¸ etcd is a keyâ€“value database that stores all the cluster data of Kubernetes.

ðŸ’¬ In simple words:

etcd is like Kubernetesâ€™s brain ðŸ§  â€”
it remembers everything about your cluster (nodes, pods, configs, secrets, etc.).


ðŸ§© Example to understand

Imagine Kubernetes is a school ðŸ«:

The Principal is the kube-apiserver
The Teachers are the Controllers, Scheduler, etc.
The Students are the Pods

Nowâ€¦ every decision, every change, every studentâ€™s detail must be recorded somewhere, right?

That record book ðŸ“– = etcd
Without etcd, the school (cluster) forgets who is in which class, what subjects exist, etc.


âš™ï¸ What exactly etcd stores?

etcd stores all the cluster state, for example:

| Data Type              | Example                              |
| ---------------------- | ------------------------------------ |
| Nodes                  | Which worker nodes exist             |
| Pods                   | Which Pods are running, their status |
| ConfigMaps             | Configuration data                   |
| Secrets                | Passwords, tokens                    |
| Deployments / Services | App definitions                      |
| Cluster info           | Roles, namespaces, networking info   |


So if your Kubernetes cluster RESTARTS, it uses etcd to restore the last known state (what was running, where, etc.).


ðŸ—ï¸ Where does etcd run?

etcd runs inside the Control Plane (Master Node)
Usually as a Pod called etcd
The kube-apiserver communicates with etcd constantly.

ðŸ§­ Every time you use a command like:

kubectl get pods


Hereâ€™s what happens:


kubectl â†’ talks to the kube-apiserver
apiserver â†’ reads data from etcd
The result (pod list) comes back to you.


| Concept    | Terraform                         | Kubernetes                      |
| ---------- | --------------------------------- | ------------------------------- |
| Storage    | `.tfstate` file (local or remote) | `etcd` database                 |
| Managed by | Terraform tool                    | kube-apiserver                  |
| Type       | File-based JSON                   | Distributed key-value store     |
| Usage      | Tracks cloud infra state          | Tracks cluster & workload state |
| Backup     | Copy `.tfstate`                   | `etcdctl snapshot save`         |

So yes â€” conceptually same idea (both store state),
but technically different systems (file vs. database).

| Component                   | Function                                                                    |
| --------------------------- | --------------------------------------------------------------------------- |
| **etcd**                    | Database â†’ stores all cluster state                                         |
| **kube-apiserver**          | Gateway â†’ talks to etcd and other control plane parts                       |
| **kube-controller-manager** | Ensures cluster state matches desired state (e.g., creates pods if missing) |
| **kube-scheduler**          | Decides on which node each pod should run                                   |
| **kubelet (on each node)**  | Runs pods and reports back to API server                                    |

ðŸ‘‰ All these components are part of the control plane,
and they all depend on etcd to store and read data.


ðŸ“Š Flow example

You create a Deployment â†’ API Server receives it.
API Server saves it to etcd.
Controller Manager reads from etcd â†’ creates ReplicaSets, Pods, etc.
Scheduler picks which node â†’ updates etcd.
Kubelet runs Pod â†’ updates status in etcd.
Everything â†’ saved and synced in etcd âœ…

| Component                   | Simple meaning    | Job                                                       |
| --------------------------- | ----------------- | --------------------------------------------------------- |
| **etcd**                    | Memory / Database | Stores everything about cluster (Pods, Nodes, Secrets...) |
| **kube-apiserver**          | Receptionist      | First contact point â€” all communication goes through it   |
| **kube-controller-manager** | Manager           | Watches etcd, fixes things automatically                  |
| **kube-scheduler**          | Planner           | Decides which node runs each Pod                          |


All these 4 together = Control Plane. âœ…

ðŸ§  Step 2: What is the â€œController Managerâ€?

The Controller Manager is just one part inside the control plane.
Its job: make sure the clusterâ€™s actual state = desired state.

Example ðŸ‘‡
You said â€œI want 3 Pods of Nginxâ€ (in Deployment YAML).

etcd stores this info.

Controller Manager checks etcd:

â€œHmm, only 2 Pods are running, but 3 are needed.â€

It creates 1 more Pod to fix it.

ðŸ’¬ So the Controller Manager reads data from etcd,
but it doesnâ€™t store anything itself â€” it just acts on data.



ðŸ§  Step 3: What is â€œetcdâ€?

etcd = Database / Memory for the control plane.

It doesnâ€™t make decisions.
It just stores everything:

Pod info
Deployment info
ConfigMaps
Secrets
Node info

Whenever anything changes in the cluster â€” itâ€™s saved to etcd.

Node components
=============
kubelet --> agent running in every node. connects the nodes and master and makes sure containers are running inside pod.
kube-proxy --> networking rules how to send traffic to pods
Container runtime --> containerd, runc, etc. runs the containers


add-ons: adds capabilities to the cluster. vpc-cni, dns, metric server, etc.

cart -> catalogue

cart -> catalogue:8080

http:://catalogue-preview:8080/health --> success

| Add-on                    | Purpose / What it does                                                |
| ------------------------- | --------------------------------------------------------------------- |
| **CoreDNS**               | Provides DNS (name â†’ IP) inside cluster (so pods can find each other) |
| **kube-proxy**            | Handles network routing inside the cluster                            |
| **Dashboard**             | Web UI for Kubernetes                                                 |
| **Metrics Server**        | Collects resource metrics (CPU, memory) for autoscaling               |
| **Ingress Controller**    | Manages external access (like load balancer)                          |
| **Network Add-ons (CNI)** | Provide pod-to-pod networking (e.g., Calico, Flannel, Weave)          |
| **Storage Add-ons (CSI)** | Manage storage volumes (e.g., EBS, Ceph, NFS)                         |
| **Monitoring tools**      | Prometheus, Grafana â€” monitor your cluster                            |
| **Logging tools**         | Fluentd, Loki â€” collect and view logs                                 |
